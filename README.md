## LLM Framework 
  - Ollama: Run LLMs locally
  - LLM Model: Mistral AI
  - Frontend UI: Gradio
  - Dataset: titanic.csv
    
# Setup Instructions (Command Prompt)
      . ollama
      - ollama list
      - ollama pull mistral # Fetch the Mistral model
      - ollama run mistral  # Run the Mistral model
